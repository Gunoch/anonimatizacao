## PDF Anonymization Tool: Overview, Current Status, and Improvement Path

**1. Intended Purpose:**

This Python program is designed to be a user-friendly desktop application (built with Tkinter) that helps users anonymize PDF documents. The core idea is to automatically detect and replace personally identifiable information (PII) within the text of a PDF. This includes:

*   **Names (PER):** People's names.
*   **Organizations (ORG):** Company or institution names.
*   **Locations (LOC):** Cities, states, addresses.
*   **CPFs (Brazilian Taxpayer Registry ID):** A common personal identifier in Brazil.
*   **Phone Numbers (TELEFONE):** Contact phone numbers.
*   **Email Addresses (EMAIL):** Electronic mail addresses.

The program aims to:
*   Allow users to load a PDF file.
*   Extract all text from the PDF.
*   Identify potential PII using a combination of:
    *   **spaCy:** A Natural Language Processing (NLP) library with pre-trained models for Named Entity Recognition (NER) in Portuguese (`pt_core_news_sm`).
    *   **Regular Expressions (Regex):** Specific patterns to find CPFs, phone numbers, and email addresses.
*   Replace the detected PII with realistic-looking fake data generated by the **Faker** library (e.g., a real name is replaced with a fake name, a real CPF with a fake CPF).
*   Save the anonymized text back into a new PDF file, preserving the general layout as much as possible (though it primarily works with text replacement, not image or complex formatting manipulation).
*   Generate a "mapping file" (in JSON format) that records which original piece of PII was replaced by which fake piece of data. This is crucial for potential, authorized de-anonymization or auditing.
*   Offer a "validation" feature that uses a small language model (**DistilGPT-2**) to generate a small snippet of text based on the anonymized content. The idea is to see if the model, when trying to continue the text, inadvertently generates PII, which might indicate that some PII was missed or that the context still strongly suggests PII.
*   Allow users to "revert" an anonymization if they have the anonymized PDF and its corresponding mapping file, or to revert the changes made in the current session.
*   Provide a basic user interface with buttons for these actions, status messages, and progress bars for longer operations.
*   Include a testing utility (`test_utils.py` and `run_tests.py`) to generate synthetic test PDFs, run anonymization on them, and (ideally) report on the accuracy and effectiveness.

**2. Current State of the Program:**

*   **Core Functionality is Present:** The application can load PDFs, extract text, attempt to detect PII using spaCy and regex, replace it with Faker data, and save the new PDF and mapping file. The UI for these steps is functional.
*   **Runtime Errors Resolved:** Previous issues with Python indentation, module import errors (like `fitz` for PyMuPDF, `spacy`, `transformers`, `faker`), and virtual environment setup have been fixed. The application now launches and can execute its main anonymization workflow.
*   **Basic Validation Implemented:** The DistilGPT-2 validation step is in place, though its effectiveness in truly catching missed PII is likely limited by the model's size and the simplicity of the check.
*   **Reversion Implemented:** Both in-session reversion and reversion from saved files are functional.
*   **Asynchronous Operations:** Some longer operations (anonymization, validation, reversion from files) are run in separate threads to prevent the UI from freezing, which is a good improvement.
*   **Testing Framework Exists (but needs work):** The `test_utils.py` script can generate test PDFs and has functions to evaluate anonymization. `run_tests.py` attempts to orchestrate these tests. However, as noted in `issues_and_improvements.md`, this part of the system is not producing detailed output or expected metrics, so its current utility for assessing accuracy is low.

**3. Current Issues and Limitations:**

Based on the code and the `issues_and_improvements.md` file (especially the findings from `relatorio_anonimizacao_oitiva.pdf`):

*   **Accuracy of PII Detection is a Major Concern:**
    *   **False Positives (Over-Anonymization):** The system wrongly substitutes common functional terms (like "Horário" - "Schedule/Time") because they might be capitalized or resemble names to the generic NER model. This fundamentally alters document meaning. This is due to:
        *   Lack of a "stop-terms" or "whitelist" dictionary (terms that should *never* be anonymized).
        *   Reliance on a generic NER model not fine-tuned for the specific domain (e.g., legal texts).
    *   **False Negatives (Under-Anonymization):** The system likely misses PII that doesn't perfectly fit the regex patterns or the NER model's training. The current validation method is too basic to reliably catch these.
    *   **Token Boundary Issues:** Substitutions can lead to concatenated or truncated words (e.g., "Almeidaimadamente"), making the document illegible. This suggests problems with how spaCy tokenization interacts with the replacement logic, or naive string replacement.
*   **Quality of Anonymization (Substitution Strategy):**
    *   **LGPD Compliance Risk:** Using Faker to generate *realistic-looking* but fake CPFs and phone numbers might still be problematic under LGPD's data minimization principle, as they could be mistaken for real data or still fall under the definition of personal data if they *could* identify someone, however unlikely.
    *   **Credibility/Plausibility:** Using unrealistic fake names for roles or locations can reduce the anonymization's credibility.
*   **Lack of Robust Validation:**
    *   The DistilGPT-2 check is a novel idea but insufficient.
    *   There's no automated "diffing" or comparison against a gold standard to systematically measure how well the anonymization worked or if it broke the document.
*   **Limited PDF Support:**
    *   **No OCR for Scanned Documents:** The system only works with PDFs that have selectable text. Scanned PDFs (images of text) will result in no text being extracted and thus no anonymization.
    *   **Complex Layouts:** The text extraction (`pagina.get_text()`) is basic. Complex PDF layouts (multi-column, tables, forms) might lead to jumbled text extraction, which in turn would severely impact detection and anonymization quality. The replacement is also a simple text replace, which might break formatting.
*   **Performance:**
    *   While threading helps the UI, processing very large documents can still be slow.
    *   The spaCy model and especially the Transformers model (DistilGPT-2) have loading times and processing overhead.
*   **Testing Framework Deficiencies:** The test suite isn't providing clear metrics, making it hard to systematically evaluate improvements or regressions.
*   **User Experience:**
    *   Error messages can be generic.
    *   No progress feedback during some lengthy sub-operations (like model loading).
    *   No interactive preview or ability to correct/guide the anonymization.

**4. Path to Near 100% Accuracy (and Overall Improvement):**

Achieving "near 100% accuracy" in PII anonymization is extremely challenging, especially with automated methods, as language is complex and context-dependent. However, significant improvements can be made by addressing the current issues:

*   **A. Enhance Detection Accuracy (Reduce False Positives & Negatives):**
    1.  **Custom NER Model (R1.1):**
        *   **Fine-tune a spaCy NER model** on a domain-specific dataset (e.g., a collection of actual legal documents like "oitivas" that have been manually annotated with PII). This is the single most impactful step for improving NER accuracy for names, locations, and organizations within that specific domain.
        *   This requires creating an annotated dataset, which is time-consuming but essential.
    2.  **Hybrid Approach with `EntityRuler` (R1.2):**
        *   Before the statistical NER model, use spaCy's `EntityRuler` to add rule-based entities. This is excellent for:
            *   Highly regular patterns (CPFs, phone numbers, specific ID formats) where regex is precise.
            *   Adding known entities from lists (e.g., a list of all judges in a state, if appropriate).
            *   Enforcing that capitalized words not in a whitelist (see below) are considered for NER.
    3.  **Whitelist/Stop-Terms Dictionary (R1.3):**
        *   Create and maintain a dictionary of terms (e.g., "Delegacia," "Juiz," "Horário," common legal terms, prepositions, articles) that should *never* be anonymized, even if they look like names or are capitalized. The system should check against this list before attempting to anonymize a detected entity.
    4.  **Improve Regex Patterns (R4.1):**
        *   Ensure all regex patterns use word delimiters (e.g., `\b` in Python regex) to prevent partial matches on substrings within words.
    5.  **Contextual Disambiguation:** For more advanced scenarios, explore techniques to understand the context of a potential PII. For example, "Apple" is a company in a business context but a fruit in a grocery context. This is harder but can involve looking at surrounding words or using more sophisticated language models.

*   **B. Refine Anonymization/Substitution Strategy:**
    1.  **Use Placeholders, Not Just Faker (R2.1):**
        *   Instead of replacing "João Silva" with "Maria Costa" (another fake name), replace it with a clear placeholder like `[NOME_PESSOA_1]`, `[CPF_1]`, `[ENDERECO_1]`.
        *   This makes it obvious what was anonymized, avoids generating new (albeit fake) PII, and better aligns with data minimization. The mapping file would then link `[NOME_PESSOA_1]` to "João Silva".
    2.  **Clearly Identifiable Fake Data (R2.2):**
        *   If synthetic data *must* be used (e.g., for system testing where placeholders break subsequent processes), ensure it's clearly identifiable as fake (e.g., CPFs that are mathematically invalid by check-digit, names like "Nome Fictício").
    3.  **Handle Tokenization and Replacement Carefully (R4.2):**
        *   When replacing text based on spaCy entities, ensure the replacement respects the original token boundaries to avoid creating malformed words.
        *   When performing replacements, it might be necessary to re-tokenize or adjust offsets carefully. Disabling unnecessary spaCy pipeline components (`tagger`, `parser`) during the substitution phase if only NER results are used can sometimes help preserve token integrity.

*   **C. Implement Robust Validation and Quality Assurance:**
    1.  **Automated Diffing/Validation (R3.1):**
        *   After anonymization, automatically compare the anonymized document (or its extracted text) against the original.
        *   Check that stop-terms were *not* altered.
        *   Check that all *known* PII (from a test set annotation) was indeed removed or replaced by a placeholder.
        *   This should be part of the test suite.
    2.  **Comprehensive Test Set (N2):**
        *   Create a diverse test set of 20-30+ real (or realistic) documents, fully annotated with all PII instances and their types. This "gold standard" is crucial for measuring precision, recall, and F1-score of the anonymization process.
    3.  **Fix and Enhance `test_utils.py`:**
        *   Ensure it runs, processes the test set, and outputs clear metrics (e.g., number of PII found, missed, wrongly identified; number of non-PII wrongly changed).
        *   Visualize results if helpful (e.g., highlighting differences).
    4.  **Manual Review (N4):**
        *   Especially after major changes, manually review a sample of anonymized documents to catch errors that automated metrics might miss.

*   **D. Add OCR Capability:**
    *   Integrate an OCR (Optical Character Recognition) engine like Tesseract (via `pytesseract` wrapper) or a cloud-based OCR service.
    *   If a PDF has no extractable text (or very little), prompt the user if they want to attempt OCR. OCR output will then be the input to the detection phase. OCR quality itself can be a challenge.

*   **E. Improve PDF Processing:**
    *   For PDFs with complex layouts, simple text extraction might not be enough. Explore libraries or techniques that can understand PDF structure better (e.g., `pdfminer.six`, or tools that can convert PDF to structured HTML first). This is a very hard problem.

*   **F. User Experience and Workflow:**
    *   **Interactive Anonymization:** Allow users to see detected PII highlighted in the document and confirm/reject/modify anonymization for each item before finalizing. This "human-in-the-loop" approach is often necessary for high accuracy.
    *   **Configuration:** Allow users to manage whitelists/blacklists, and perhaps even custom regex patterns, via the UI or configuration files.

*   **G. Documentation and Reproducibility (N3):**
    *   Document all parameters, model versions (spaCy, Transformers), and Faker seeds used to ensure that anonymization runs can be reproduced if needed for audits.

By systematically implementing these (especially A, B, and C), the application can move towards much higher accuracy and reliability. However, 100% automated accuracy is a very high bar; a combination of automated tools and human review/guidance is often the most practical path for critical anonymization tasks.
